# Data_Science_Internship_G2_BWF_Malaika_Ahmed 
<br>
- This repository is for task submission of Data Science Fellowship at Bytewise Limited

- Author : Malaika Ahmed

_______________________________________


# Bytewise Data Science Internship - 100 Days Journey

## Overview
This repository contains the work and learning journey throughout my **100-day Data Science internship at Bytewise**. During the internship, I gained hands-on experience and knowledge in multiple aspects of Data Science, ranging from foundational concepts like Python and Git to advanced topics like deep learning and natural language processing (NLP). I worked on multiple projects, both individual and team-based, including **Data Analysis, Model Building**, and a **Capstone Project** where I built a **Book Recommender System**.

## Internship Breakdown

### 1. **Foundations (Day 1 - 30)**

- **Introduction to Git**: Understanding version control using Git, setting up repositories, and using GitHub for projects submission.
- **Jupyter Notebook**: Writing and running Python code in Jupyter Notebooks, which became an essential tool for data analysis and model building.
- **Python Basics**: 
  - Core Python concepts: variables, data types, loops, functions, and error handling.
  - Object-Oriented Programming (OOP): Classes, objects, inheritance, and polymorphism.
  - Data Structures: Lists, tuples, dictionaries, and sets.

### 2. **Libraries for Data Science (Day 31 - 50)**

- **NumPy**: Working with arrays, vectorized operations, and linear algebra using NumPy.
- **Pandas**: Data manipulation and cleaning with Pandas DataFrames, handling missing data, and exploring real-world datasets.
- **Matplotlib & Seaborn**: Data visualization for better insights; creating various types of plots like histograms, bar charts, scatter plots, and heatmaps.
- **Scikit-learn**: Building machine learning models, including regression and classification, using scikit-learn.

### 3. **Mathematics for Data Science (Day 51 - 60)**

- **Calculus**: Concepts like differentiation and integration to understand optimization algorithms used in machine learning.
- **Linear Algebra**: Vectors, matrices, eigenvalues, eigenvectors, and their applications in machine learning algorithms (e.g., PCA, Singular Value Decomposition).

### 4. **Machine Learning Fundamentals (Day 61 - 80)**

- **Regression from Scratch**: Implemented linear regression from the ground up to understand the underlying mechanics and optimization techniques.
- **Regression using scikit-learn**: Built regression models using scikit-learn, evaluated their performance using metrics like RMSE, MAE, and RÂ² score.
- **Classification from Scratch**: Developed classification algorithms (e.g., Logistic Regression) from scratch, learning the mathematics and theory behind them.
- **Classification using scikit-learn**: Built and evaluated various classifiers, such as Decision Trees, Random Forests, and Support Vector Machines.
- **Evaluation Metrics**: Accuracy, precision, recall, F1-score, confusion matrix, ROC-AUC, and how to interpret them.
- **Cross-Validation**: Implemented cross-validation techniques to avoid overfitting and ensure model generalization.
- **Overfitting and Underfitting**: Identified and mitigated overfitting and underfitting issues with model tuning and regularization techniques.
- **Hyperparameter Tuning**: Used GridSearchCV and RandomizedSearchCV to optimize hyperparameters for better model performance.
- **Preprocessing**: Applied preprocessing steps such as scaling, encoding categorical variables, and imputing missing values using scikit-learn.

### 5. **Advanced Topics (Day 81 - 100)**

- **Dimensionality Reduction**: Implemented PCA (Principal Component Analysis) and t-SNE for reducing the feature space and improving model efficiency.
- **K-Means Clustering**: Learned unsupervised learning through K-Means clustering, used for segmenting data into groups.
- **Neural Networks**: Basic understanding of Artificial Neural Networks (ANN) and how they work.
- **Deep Learning**:
  - **Convolutional Neural Networks (CNN)**: Implemented CNN for image classification tasks.
  - **Recurrent Neural Networks (RNN)**: Explored RNNs for sequential data like time-series and text data.
  - **Long Short-Term Memory (LSTM)**: Delved into LSTMs for handling long-term dependencies in sequential data.
- **Natural Language Processing (NLP)**: Learned the basics of NLP, including text preprocessing, tokenization, stemming, lemmatization, and building models for text classification.

### 6. **Projects**

#### **End of Month Projects:**

1. **Mini-Project 1: Data Analysis**  
   - **Description**: Understanding the enrollment trends of online courses offered by a university and extracting important insights from the dataset.
   - **Goal**: Identifying the factors that contribute to higher enrollment and determining if the course type (online or classroom) is a significant factor in enrollment numbers.
   - **Key Concepts**: Statistics, Data Cleaning, Transformations, Data Visualizations

2. **Mini-Project 2: Regression Models**  
   - **Description**: In this mini-project, I picked a titanic dataset related to a regression problem, cleaned it, performed exploratory data analysis (EDA), applied data transformations, and conducted statistical tests (such as hypothesis testing). 
   - **Goal**: Built a variety of regression models including baseline models (SVM, Linear Regression, Random Forest, Decision Trees, Gradient Boosting), and also implemented an Artificial Neural Network (ANN).
   - **Key Concepts**: Model Evaluation, Error Curves (Overfitting/Underfitting), Convolutional Neural Networks (1D CNN followed by ANN layers)

3. **Capstone Project: Book Recommender System**  
   - **Description**: The capstone project focused on building a book recommendation system using **popularity-based** and **collaborative filtering** techniques.
   - **Goal**: Recommend books based on similarity scores using **Euclidean Distance**.
   - **Tools**: PyCharm, Colab
   - **Languages**: Python, HTML, CSS
   - **Methods Used**: 
     - Collaborative Filtering
     - Popularity-Based Recommendation
     - Data Preprocessing and Transformation

## Key Learnings

- **Data Science Skills**: Acquired proficiency in Python and key data science libraries such as NumPy, Pandas, scikit-learn, Matplotlib, and Seaborn.
- **Machine Learning**: Developed a deep understanding of machine learning algorithms, including linear and logistic regression, decision trees, clustering, and neural networks.
- **Model Optimization**: Gained hands-on experience in improving model performance through cross-validation, hyperparameter tuning, and addressing overfitting and underfitting.
- **Deep Learning**: Applied deep learning concepts to solve complex tasks in image and text data using CNNs, RNNs, and LSTMs.
- **Natural Language Processing**: Built models for text analysis and classification, and understood key concepts in text preprocessing.

## Repository Contents

- **Notebooks**: 40 Jupyter notebooks containing the work done for each topic, with detailed explanations and code for data exploration, model building, and evaluation.
- **Scripts**: Python scripts for machine learning algorithms, including regression and classification models built from scratch and using scikit-learn.
- **Capstone Project**: The code for the Book Recommender System, including data collection, preprocessing, and recommendation algorithm implementation.
